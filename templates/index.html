<!DOCTYPE html>
<html lang="pt">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reconhecimento de Gestos</title>
    <style>
        body {
            text-align: center;
            font-family: Arial, sans-serif;
        }
        video {
            width: 100%;
            max-width: 500px;
            height: auto;
            border: 2px solid black;
        }
        #hand-state, #exercise, #recent-gestures {
            font-size: 1.5em;
            margin-top: 10px;
        }
        .buttons {
            margin-top: 20px;
        }
        button {
            font-size: 1.2em;
            padding: 10px 20px;
            margin: 5px;
            cursor: pointer;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            max-width: 500px;
            height: 100%;
            pointer-events: none; /* Permite interação com o vídeo abaixo */
        }
    </style>
</head>
<body>
    <h1>Reconhecimento de Gestos</h1>
    <div style="position: relative; display: inline-block;">
        <video id="video" autoplay playsinline></video>
        <canvas id="canvas"></canvas>
    </div>
    <p id="hand-state">Gesto: Aguardando...</p>
    <p id="exercise">Exercicio Realizado: Nenhum</p>
    <p id="objective"></p>
    <p id="benefit"></p>
    <p id="recent-gestures">Sequencia de Gestos: []</p>

    <div class="buttons">
        <button id="start-btn">Iniciar Captura</button>
        <button id="pause-btn">Parar Captura</button>
        <button id="clear-btn">Limpar Gestos</button>
        <button id="switch-camera-btn">Trocar Camera</button>
    </div>

    <!-- Inclua as bibliotecas do MediaPipe -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>

    <script>
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        const canvasCtx = canvas.getContext("2d");
        const handStateText = document.getElementById("hand-state");
        const exerciseText = document.getElementById("exercise");
        const objectiveText = document.getElementById("objective");
        const benefitText = document.getElementById("benefit");
        const recentGesturesText = document.getElementById("recent-gestures");
        const startBtn = document.getElementById("start-btn");
        const pauseBtn = document.getElementById("pause-btn");
        const clearBtn = document.getElementById("clear-btn");
        const switchCameraBtn = document.getElementById("switch-camera-btn");

        let ws;
        let isDetectionActive = false;
        let intervalId = null;
        let isFrontCamera = true; // Variável para alternar entre câmera frontal e traseira
        let currentStream = null; // Variável para armazenar o stream atual
        let camera; // Variável para armazenar a instância da câmera do MediaPipe
        let ultimoExercicio = null; // Variável para armazenar o último exercício detectado

        // Configurações do MediaPipe Hands
        const hands = new Hands({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
        });

        hands.setOptions({
            maxNumHands: 1,
            modelComplexity: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5,
        });

        // Função para desenhar os landmarks
        hands.onResults((results) => {
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
            canvasCtx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

            if (results.multiHandLandmarks) {
                for (const landmarks of results.multiHandLandmarks) {
                    // Desenha os landmarks e as conexões
                    drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, {
                        color: "#00FF00",
                        lineWidth: 2,
                    });
                    drawLandmarks(canvasCtx, landmarks, {
                        color: "#FF0000",
                        lineWidth: 1,
                        radius: 2, // Reduz o tamanho dos pontos
                    });
                }
            }

            canvasCtx.restore();
        });

        // Função para parar o stream atual
        function stopWebcam() {
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
                currentStream = null;
            }
            if (camera) {
                camera.stop(); // Para a câmera do MediaPipe
            }
        }

        // Função para pedir permissão e iniciar a câmera
        async function startWebcam(useFront = true) {
            stopWebcam(); // Para o stream atual antes de iniciar um novo

            // Desativa temporariamente os logs de erro
            const originalConsoleError = console.error;
            console.error = () => {};

            try {
                const constraints = {
                    video: {
                        facingMode: useFront ? "user" : { exact: "environment" } // Força o uso da câmera traseira
                    }
                };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                currentStream = stream;

                // Ajusta o tamanho do canvas para o tamanho do vídeo
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                };

                // Inicializa o MediaPipe Hands para processar o vídeo
                camera = new Camera(video, {
                    onFrame: async () => {
                        try {
                            await hands.send({ image: video });
                        } catch (error) {
                            console.error("Erro ao processar o frame:", error);
                        }
                    },
                    width: 640,
                    height: 480,
                });
                camera.start();
            } catch (error) {
                console.error("Erro ao acessar a câmera:", error);
            } finally {
                // Restaura a função original de console.error
                console.error = originalConsoleError;
            }
        }

        // Função para ler o texto em voz alta
        function lerTexto(texto) {
            const utterance = new SpeechSynthesisUtterance(texto);
            const voices = window.speechSynthesis.getVoices();
            utterance.voice = voices.find(voice => voice.lang === 'pt-BR') || voices[0]; // Usa uma voz em português, se disponível
            utterance.rate = 1; // Velocidade normal
            utterance.pitch = 1; // Tom normal
            window.speechSynthesis.speak(utterance);
        }

        // WebSocket para conectar com o backend
        function connectWebSocket() {
            ws = new WebSocket("wss://e6fe-2804-d4b-af3e-4800-d1a4-f92f-59a0-1ddc.ngrok-free.app/ws");

            ws.onopen = () => {
                console.log("WebSocket conectado!");
            };

            ws.onmessage = function(event) {
                console.log("Resposta do servidor:", event.data);

                // Processa a resposta JSON
                const response = JSON.parse(event.data);
                const handState = response.hand_state;
                const exercise = response.exercise;
                const objective = response.objective;
                const benefit = response.benefit;
                const recentGestures = response.recent_gestures;

                // Atualiza o estado da mão
                handStateText.innerText = "Estado da Mao: " + handState;

                // Atualiza o exercício realizado apenas se um novo exercício for detectado
                if (exercise && exercise !== "Nenhum" && exercise !== ultimoExercicio) {
                    exerciseText.innerText = "Exercicio Realizado: " + exercise;
                    objectiveText.innerText =  objective;
                    benefitText.innerText =   benefit;

                    // Ler o texto em voz alta
                    const textoParaLer = `${exercise}. ${objective}. ${benefit}`;
                    lerTexto(textoParaLer);

                    // Atualiza o último exercício detectado
                    ultimoExercicio = exercise;
                }

                // Atualiza a sequência de gestos
                recentGesturesText.innerText = "Gestos: " + JSON.stringify(recentGestures);
            };

            ws.onclose = function() {
                console.log("WebSocket fechado. Reconectando...");
                setTimeout(connectWebSocket, 2000); // Tentar reconectar após 2 segundos
            };

            ws.onerror = function(error) {
                console.error("Erro no WebSocket:", error);
            };
        }

        // Função para capturar frames da câmera e enviá-los para o servidor
        function captureAndSendFrame() {
            if (!video.videoWidth || !isDetectionActive) return;

            const tempCanvas = document.createElement("canvas");
            tempCanvas.width = video.videoWidth;
            tempCanvas.height = video.videoHeight;
            const tempCtx = tempCanvas.getContext("2d");

            tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);

            const dataURL = tempCanvas.toDataURL("image/jpeg", 0.8); // Comprimir a imagem (qualidade 80%)
            ws.send(dataURL);
        }

        // Inicia a detecção
        startBtn.addEventListener("click", () => {
            isDetectionActive = true;
            console.log("Detecção iniciada!");
            if (!intervalId) {
                intervalId = setInterval(captureAndSendFrame, 200);
            }
        });

        // Pausa a detecção
        pauseBtn.addEventListener("click", () => {
            isDetectionActive = false;
            console.log("Detecção pausada!");
        });

        // Limpa a sequência de gestos
        clearBtn.addEventListener("click", () => {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ action: "clear" }));
                console.log("Sequência de gestos limpa!");
            }
        });

        // Alternar entre câmera frontal e traseira
        switchCameraBtn.addEventListener("click", () => {
            isFrontCamera = !isFrontCamera;
            startWebcam(isFrontCamera);
        });

        // Ao carregar a página, iniciar a câmera e conectar WebSocket
        startWebcam();
        connectWebSocket();
    </script>
</body>
</html>